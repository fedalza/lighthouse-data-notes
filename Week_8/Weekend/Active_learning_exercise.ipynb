{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the titanic dataset here: https://drive.google.com/file/d/0Bz9_0VdXvv9bbVhpOEMwUDJ2elU/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will simulate active learning. We will keep the small sample of observations for testing and we will test how quality of the model rises when we use active learning to choose labeled observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('titanic_dataset.csv')\n",
    "\n",
    "# drop useless columns\n",
    "df.drop(columns=['Cabin','Name','Ticket'], inplace = True)\n",
    "\n",
    "# TEST SAMPLE\n",
    "# USE THIS SAMPLE ONLY FOR TESTING\n",
    "test_df = df.sample(n=100, random_state=42)\n",
    "# KEEP ONLY THOSE WHO ARE NOT IN THE TEST SET\n",
    "df = df[~df.PassengerId.isin(test_df.PassengerId.tolist())]\n",
    "\n",
    "# FIT THE FIRST MODEL ONLY ON THE DATAFRAME START_DF\n",
    "start_df = df.sample(n=100, random_state=42)\n",
    "# DROP OBS FROM START_DF FROM DF\n",
    "df = df[~df.PassengerId.isin(start_df.PassengerId.tolist())]\n",
    "\n",
    "# Preprocessing of data\n",
    "# DROP NA\n",
    "start_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch      Fare  \\\n288          289         1       2    male  42.0      0      0   13.0000   \n416          417         1       2  female  34.0      1      1   32.5000   \n329          330         1       1  female  16.0      0      1   57.9792   \n587          588         1       1    male  60.0      1      1   79.2000   \n686          687         0       3    male  14.0      4      1   39.6875   \n..           ...       ...     ...     ...   ...    ...    ...       ...   \n438          439         0       1    male  64.0      1      4  263.0000   \n687          688         0       3    male  19.0      0      0   10.1708   \n10            11         1       3  female   4.0      1      1   16.7000   \n173          174         0       3    male  21.0      0      0    7.9250   \n592          593         0       3    male  47.0      0      0    7.2500   \n\n    Embarked  \n288        S  \n416        S  \n329        C  \n587        C  \n686        S  \n..       ...  \n438        S  \n687        S  \n10         S  \n173        S  \n592        S  \n\n[79 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>288</th>\n      <td>289</td>\n      <td>1</td>\n      <td>2</td>\n      <td>male</td>\n      <td>42.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>416</th>\n      <td>417</td>\n      <td>1</td>\n      <td>2</td>\n      <td>female</td>\n      <td>34.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>32.5000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>329</th>\n      <td>330</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>16.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>57.9792</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>587</th>\n      <td>588</td>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>60.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>79.2000</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>686</th>\n      <td>687</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>14.0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>39.6875</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>438</th>\n      <td>439</td>\n      <td>0</td>\n      <td>1</td>\n      <td>male</td>\n      <td>64.0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>263.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>687</th>\n      <td>688</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10.1708</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>16.7000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>174</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>21.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>592</th>\n      <td>593</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>47.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n<p>79 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "start_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for categorical data\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "def encoder(model,data, columns, fit=False):\n",
    "    if fit:  \n",
    "        encoded = model.fit_transform(data.loc[:,columns]).toarray()\n",
    "    else:\n",
    "        encoded = model.transform(data.loc[:,columns]).toarray()\n",
    "    encoded = pd.DataFrame(encoded, index = data.index, columns=[ohe.get_feature_names(columns)])\n",
    "    return pd.merge(data.PassengerId,encoded,left_index=True,right_index=True,how='left')\n",
    "\n",
    "encoded_train = encoder(ohe,start_df,['Sex','Embarked'],fit=True)\n",
    "encoded_test = encoder(ohe,test_df,['Sex','Embarked'])\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "def scaler(model, data, columns, fit=False):\n",
    "    if fit:\n",
    "        scaled = pd.DataFrame(model.fit_transform(data.loc[:,columns]),index = data.index,columns=columns)\n",
    "    else:\n",
    "        scaled = pd.DataFrame(model.transform(data.loc[:,columns]),index = data.index,columns=columns)\n",
    "    return pd.merge(data.PassengerId,scaled,left_index=True,right_index=True,how='left')\n",
    "\n",
    "scaled_train = scaler(sc,start_df,['Pclass', 'Age', 'SibSp', 'Parch'],fit=True)\n",
    "scaled_test = scaler(sc,test_df,['Pclass', 'Age', 'SibSp', 'Parch'])\n",
    "\n",
    "X = pd.merge(scaled_train.drop(columns=['PassengerId']),encoded_train.drop(columns=['PassengerId']),left_index=True,right_index=True)\n",
    "X_test = pd.merge(scaled_test.drop(columns=['PassengerId']),encoded_test.drop(columns=['PassengerId']),left_index=True,right_index=True)\n",
    "y = start_df.Survived\n",
    "y_test = test_df.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SVC()"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1. fit the first model only on the **start_df** using **SVM** and evaluate accuracy, precision and recall on test_df\n",
    "2. in each iteration, add 10 observations (choose the observation using active learning approach) from **df** to your trainset, refit the model and evaluate on test_df again\n",
    "3. the goal is to converge to the optimal solution as fast as possible by choosing **right** observations in each iteration\n",
    "4. plot the graphs for each eval metric, where on the axis x is iteration number, on y is the metric value for that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(79,)"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "clf.decision_function(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "acc_hist=[]\n",
    "pre_hist=[]\n",
    "rec_hist=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evluation metrics history\n",
    "acc_hist=[]\n",
    "pre_hist=[]\n",
    "rec_hist=[]\n",
    "iteration_nb=[]\n",
    "i = 0 # iteration_nb\n",
    "# SVM classifier\n",
    "X_i = X\n",
    "y_i = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 691 10\n"
    }
   ],
   "source": [
    "for k in range(1):\n",
    "        # fit model to current data\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_i,y_i)\n",
    "\n",
    "    acc_hist.append(metrics.accuracy_score(y_test,clf.predict(X_test)))\n",
    "    pre_hist.append(metrics.precision_score(y_test,clf.predict(X_test)))\n",
    "    rec_hist.append(metrics.recall_score(y_test,clf.predict(X_test)))\n",
    "    i += 1\n",
    "    iteration_nb.append(i)\n",
    "    \n",
    "    # next 10 observations\n",
    "    next_df = df.sample(n=min([10,len(df)]),random_state=42)\n",
    "    \n",
    "    print(i,len(df),len(next_df))\n",
    "    next_df.dropna(inplace=True)\n",
    "    if len(next_df)>0:\n",
    "        encoded_next = encoder(ohe,next_df,['Sex','Embarked'])\n",
    "        scaled_next = scaler(sc,next_df,['Pclass', 'Age', 'SibSp', 'Parch'])\n",
    "\n",
    "        X_next = pd.merge(scaled_next.drop(columns=['PassengerId']),encoded_next.drop(columns=['PassengerId']),left_index=True,right_index=True)\n",
    "        y_next = next_df.Survived\n",
    "             \n",
    "        decision = np.abs(list(clf.decision_function(X_next))) \n",
    "        ind = np.argpartition(decision, 2)\n",
    "        indy_to_drop = X_next.iloc[ind[0:2]].index\n",
    "        \n",
    "    \n",
    "        X_i = pd.concat([X_i,X_next.iloc[ind[0:2]]],ignore_index=True)\n",
    "        y_i = pd.concat([y_i,y_next.iloc[ind[0:2]]],ignore_index=True)\n",
    "\n",
    "    # drop observations from global df\n",
    "    df = df[~df.index.isin([indy_to_drop])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch     Fare  \\\n0              1         0       3    male  22.0      1      0   7.2500   \n1              2         1       1  female  38.0      1      0  71.2833   \n2              3         1       3  female  26.0      0      0   7.9250   \n3              4         1       1  female  35.0      1      0  53.1000   \n4              5         0       3    male  35.0      0      0   8.0500   \n..           ...       ...     ...     ...   ...    ...    ...      ...   \n882          883         0       3  female  22.0      0      0  10.5167   \n883          884         0       2    male  28.0      0      0  10.5000   \n887          888         1       1  female  19.0      0      0  30.0000   \n888          889         0       3  female   NaN      1      2  23.4500   \n890          891         0       3    male  32.0      0      0   7.7500   \n\n    Embarked  \n0          S  \n1          C  \n2          S  \n3          S  \n4          S  \n..       ...  \n882        S  \n883        S  \n887        S  \n888        S  \n890        Q  \n\n[689 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>882</th>\n      <td>883</td>\n      <td>0</td>\n      <td>3</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10.5167</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>883</th>\n      <td>884</td>\n      <td>0</td>\n      <td>2</td>\n      <td>male</td>\n      <td>28.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10.5000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>23.4500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.7500</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>689 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 191
    }
   ],
   "source": [
    "df[~df.index.isin(indy_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Int64Index([339, 419], dtype='int64')"
     },
     "metadata": {},
     "execution_count": 188
    }
   ],
   "source": [
    "indy_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Int64Index([339, 419], dtype='int64')"
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}