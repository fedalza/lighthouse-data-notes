{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the CIFAR10 data\n",
    "The data can be found directly in the package keras (`keras.datasets.cifar10`).\n",
    "\n",
    "```python\n",
    "cifar10 = keras.datasets.cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "Build the neural network (CNN) to predict the object in the images. Try to do it on your own first before consulting peers or the tutorials on the internet. If you are stuck early, reach out to our mentors who will point you in the right direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "152821760/170498071 [=========================>....] - ETA: 8s"
     ]
    }
   ],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32')/255\n",
    "test_images = test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential()\n",
    "# filter : Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution). \n",
    "# kernel_size : An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n",
    "# VGG BLOCK 1 - VISUAL GEOMETRY GROUP\n",
    "# We can add weight regularization to the convolutional layers and the fully connected layers by defining the “kernel_regularizer” argument and specifying the type of regularization. In this case, we will use L2 weight regularization, the most common type used for neural networks and a sensible default weighting of 0.001\n",
    "cnn.add(Conv2D(filters = 32,kernel_size = (3,3), activation = 'relu', input_shape = (32,32,3),padding='same', kernel_regularizer=l2(0.001)))\n",
    "cnn.add(Conv2D(filters = 32,kernel_size = (3,3), activation = 'relu',padding='same', kernel_regularizer=l2(0.001)))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2), strides = (1,1)))\n",
    "cnn.add(Dropout(0.2))# -> Regularization: The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting.\n",
    "# VGG BLOCK 2 - VISUAL GEOMETRY GROUP\n",
    "cnn.add(Conv2D(filters = 64,kernel_size = (3,3), activation = 'relu', input_shape = (32,32,3),padding='same', kernel_regularizer=l2(0.001)))\n",
    "cnn.add(Conv2D(filters = 64,kernel_size = (3,3), activation = 'relu',padding='same', kernel_regularizer=l2(0.001)))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2), strides = (1,1)))\n",
    "cnn.add(Dropout(0.2))\n",
    "# VGG BLOCK 3 - VISUAL GEOMETRY GROUP\n",
    "cnn.add(Conv2D(filters = 128,kernel_size = (3,3), activation = 'relu', input_shape = (32,32,3),padding='same', kernel_regularizer=l2(0.001)))\n",
    "cnn.add(Conv2D(filters = 128,kernel_size = (3,3), activation = 'relu',padding='same', kernel_regularizer=l2(0.001)))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2), strides = (1,1)))\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(128, activation='relu'))\n",
    "cnn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "334/334 [==============================] - 638s 2s/step - loss: 2.1081 - accuracy: 0.3078\n",
      "Epoch 2/5\n",
      "334/334 [==============================] - 632s 2s/step - loss: 1.5504 - accuracy: 0.4835\n",
      "Epoch 3/5\n",
      "334/334 [==============================] - 605s 2s/step - loss: 1.2787 - accuracy: 0.5795\n",
      "Epoch 4/5\n",
      "334/334 [==============================] - 582s 2s/step - loss: 1.1566 - accuracy: 0.6202\n",
      "Epoch 5/5\n",
      "334/334 [==============================] - 584s 2s/step - loss: 1.0644 - accuracy: 0.6522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f209c2d8f70>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(train_images, train_labels, epochs=5, batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.9679 - accuracy: 0.6609\n",
      "test accuracy:  0.6608999967575073 test loss:  0.9678670167922974\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = cnn.evaluate(test_images,test_labels)\n",
    "print('test accuracy: ',test_acc, 'test loss: ', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaded_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2c305eb18537>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#loaded_model = model_from_json(loaded_model_json)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# load weights into new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded model from disk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loaded_model' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "\n",
    "## load json and create model\n",
    "#json_file = open('model.json', 'r')\n",
    "#loaded_model_json = json_file.read()\n",
    "#json_file.close()\n",
    "#loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "cnn.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
