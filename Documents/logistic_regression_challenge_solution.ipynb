{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Download your data and load them into the Python.\n",
    "You can find them [**here**](https://drive.google.com/file/d/0Bz9_0VdXvv9bX0MzUEhVdmpCc3c/view?usp=sharing).\n",
    "\n",
    "- Features and response variables are in different files\n",
    "- be careful about number of spaces between the values in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with open('/Users/jurajkapasny/Drive/Data/UCI HAR Dataset/train/X_train.txt') as inputfile:\n",
    "    for row in csv.reader(inputfile):\n",
    "        results.append([float(i) for i in re.sub(\"\\s+\",\",\",row[0].strip()).split(\",\")])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(results)\n",
    "#train_X_str = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>551</th>\n",
       "      <th>552</th>\n",
       "      <th>553</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "      <th>560</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074323</td>\n",
       "      <td>-0.298676</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158075</td>\n",
       "      <td>-0.595051</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414503</td>\n",
       "      <td>-0.390748</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404573</td>\n",
       "      <td>-0.117290</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087753</td>\n",
       "      <td>-0.351471</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.288585 -0.020294 -0.132905 -0.995279 -0.983111 -0.913526 -0.995112   \n",
       "1  0.278419 -0.016411 -0.123520 -0.998245 -0.975300 -0.960322 -0.998807   \n",
       "2  0.279653 -0.019467 -0.113462 -0.995380 -0.967187 -0.978944 -0.996520   \n",
       "3  0.279174 -0.026201 -0.123283 -0.996091 -0.983403 -0.990675 -0.997099   \n",
       "4  0.276629 -0.016570 -0.115362 -0.998139 -0.980817 -0.990482 -0.998321   \n",
       "\n",
       "        7         8         9    ...       551       552       553       554  \\\n",
       "0 -0.983185 -0.923527 -0.934724  ... -0.074323 -0.298676 -0.710304 -0.112754   \n",
       "1 -0.974914 -0.957686 -0.943068  ...  0.158075 -0.595051 -0.861499  0.053477   \n",
       "2 -0.963668 -0.977469 -0.938692  ...  0.414503 -0.390748 -0.760104 -0.118559   \n",
       "3 -0.982750 -0.989302 -0.938692  ...  0.404573 -0.117290 -0.482845 -0.036788   \n",
       "4 -0.979672 -0.990441 -0.942469  ...  0.087753 -0.351471 -0.699205  0.123320   \n",
       "\n",
       "        555       556       557       558       559       560  \n",
       "0  0.030400 -0.464761 -0.018446 -0.841247  0.179941 -0.058627  \n",
       "1 -0.007435 -0.732626  0.703511 -0.844788  0.180289 -0.054317  \n",
       "2  0.177899  0.100699  0.808529 -0.848933  0.180637 -0.049118  \n",
       "3 -0.012892  0.640011 -0.485366 -0.848649  0.181935 -0.047663  \n",
       "4  0.122542  0.693578 -0.615971 -0.847865  0.185151 -0.043892  \n",
       "\n",
       "[5 rows x 561 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Create Binary target variable: categories 1,2,3 --> 1, categories 4,5,6 --> 0 \n",
    "This will represent binary variable indicating if person is walking or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with open('/Users/jurajkapasny/Drive/Data/UCI HAR Dataset/train/y_train.txt') as inputfile:\n",
    "    for row in csv.reader(inputfile):\n",
    "        results.append([float(i) for i in re.sub(\"\\s+\",\",\",row[0].strip()).split(\",\")])\n",
    "train_y = pd.DataFrame(results)\n",
    "train_y.loc[:,\"walking\"] = 0\n",
    "train_y.loc[train_y[0].isin([1,2,3]), \"walking\"] = 1\n",
    "train_y.columns = [\"category\",\"walking\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>walking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category  walking\n",
       "0       5.0        0\n",
       "1       5.0        0\n",
       "2       5.0        0\n",
       "3       5.0        0\n",
       "4       5.0        0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "+ Create Univariate Binary Logistic Regression with feature number 54, which represents `tGravityAcc-min()-Y`: gravity acceleration signals in direction of Y\n",
    "+ Compare the results of Logistic regressions from different Python packages (sklearn, statsmodel)\n",
    "+ Plot the FIT of predicted probabilities to the original values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_cat = train_y[\"category\"].values\n",
    "y_bin = train_y.walking.values\n",
    "X_train_mt = X_train[54].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05648273],\n",
       "       [ 0.10276411],\n",
       "       [ 0.10276411],\n",
       "       ...,\n",
       "       [-0.06891924],\n",
       "       [-0.0400087 ],\n",
       "       [-0.04749059]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(fit_intercept=True)\n",
    "lr.fit(X_train_mt, y_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.08782292])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict_proba(X_train_mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking just probability of an event\n",
    "prob_walking = []\n",
    "for pred in predictions:\n",
    "    prob_walking.append(pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fae49b86ad0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(8, 6))\n",
    "x = plt.scatter(X_train_mt.ravel(), y_bin, color='black', zorder=20, label = \"Original\")\n",
    "y = plt.scatter(X_train_mt.ravel(), prob_walking, color='blue', zorder=20, label = \"Predictions\")\n",
    "plt.legend(handles=[x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "- Try to fit Binary Logistic Regression with all the features? How many are significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p values for particular beta coeficient need to be lower than 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "Now, let's fit Multinomial Logistic regression to predict all categories. Firstly, we can start with **Univariate** model for these features number separately:\n",
    "+ 4\n",
    "+ 54\n",
    "- 19\n",
    "\n",
    "Check the contingency matrix to see the effect of particular features!! (each feature can be good in predicting different categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contingency_matrix(predictions, original):\n",
    "    pred = list(predictions)\n",
    "    orig = list(original)\n",
    "    matrix = pd.DataFrame()\n",
    "    matrix[\"pred\"] = pred\n",
    "    matrix[\"orig\"] = orig\n",
    "    res = pd.DataFrame(matrix.groupby([\"pred\",\"orig\"]).size(),columns=[\"count\"])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = train_y[\"category\"].values\n",
    "X_train_mt = X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_mlr_fitting(trainset_df, target, feature):\n",
    "    X_train_mt = trainset_df[[feature]].values.reshape(-1,1)\n",
    "    mlr = LogisticRegression(fit_intercept=True)\n",
    "    mlr.fit(X_train_mt, target)\n",
    "    predictions = mlr.predict(X_train_mt)\n",
    "    \n",
    "    return mlr,predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr, predictions = uni_mlr_fitting(X_train,y_cat, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3503"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predictions == y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th>orig</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>1059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">3.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5.0</th>\n",
       "      <th>4.0</th>\n",
       "      <td>1137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">6.0</th>\n",
       "      <th>1.0</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count\n",
       "pred orig       \n",
       "1.0  1.0    1059\n",
       "     2.0     872\n",
       "     3.0     308\n",
       "     4.0       1\n",
       "     6.0      16\n",
       "3.0  1.0     152\n",
       "     2.0     192\n",
       "     3.0     677\n",
       "     6.0       3\n",
       "5.0  4.0    1137\n",
       "     5.0    1230\n",
       "     6.0     851\n",
       "6.0  1.0      15\n",
       "     2.0       9\n",
       "     3.0       1\n",
       "     4.0     148\n",
       "     5.0     144\n",
       "     6.0     537"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contingency_matrix(predictions,y_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same proces for other two features and compare contingency matrices!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "\n",
    "Fit the Multinomial Logistic Regression model again. Now, try to choose **all** important features we have in the dataset. Who will get the best predictions with the smallest number of features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7 (Stretch)\n",
    "Create your own function for Stepwise selection. Use either sklearn or statsmodel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
